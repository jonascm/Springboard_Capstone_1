{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Election for Single Criterion Recommender System (I)\n",
    "\n",
    "## 1. Selection of the algorithm\n",
    "\n",
    "Let's use the structure on https://github.com/NicolasHug/Surprise/blob/master/examples/benchmark.py to evaluate different algorithms to use on the recommender system with the data we have.\n",
    "\n",
    "In any case I want to compare item-based and user-based approaches when possible. I believe SVD does not allow for such.\n",
    "\n",
    "Once I have done that, I will implement that specific one on the recommender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import six\n",
    "from tabulate import tabulate\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is **user-based**, if we want **item-based** we need to specify the parameter to be false.\n",
    "\n",
    "The default similarity is **MSD**.\n",
    "\n",
    "Anything else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'SVD':SVD, 'NMF':NMF, 'SlopeOne':SlopeOne, 'KNNBasic':KNNBasic, 'KNNWithMeans':KNNWithMeans, \n",
    "           'KNNBaseline':KNNBaseline,'CoClustering':CoClustering, 'BaselineOnly':BaselineOnly, \n",
    "           'NormalPredictor':NormalPredictor}\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass(), data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n User-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'msd', 'user_based': False}\n",
    "classes = {'KNNBasic':KNNBasic(sim_options=sim_options), \n",
    "           'KNNWithMeans':KNNWithMeans(sim_options=sim_options), \n",
    "           'KNNBaseline':KNNBaseline(sim_options=sim_options)}\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass, data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n Item-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it seems that KNN performs a bit better. Even though we cannot see a delay in run time, it is more expensive to go item-based, so we won't by default\n",
    "\n",
    "How about another similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_options = {'name': 'msd'}\n",
    "classes = {'KNNBasic':KNNBasic(sim_options=sim_options), \n",
    "           'KNNWithMeans':KNNWithMeans(sim_options=sim_options), \n",
    "           'KNNBaseline':KNNBaseline(sim_options=sim_options)}\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass, data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n Item-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 2. Example of implementation\n",
    "\n",
    "Okay, now we know we want to use a kNN Baseline algorithm (for now). So... \n",
    "\n",
    "* for an existing user with some ratings, what would it be the best hotels? How do we do that?\n",
    "* what are similar hotels to a specific one?\n",
    "* What if a user doesn't have any ratings? Should we just add the most popular hotels for the area?\n",
    "\n",
    "Let's start again by training the algorithm. Then, I will chose both: user with ratings and user without ratings, and will look at the output. Finally, let's try to look at hotels similar to a specific one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "\n",
      "Top 10 hotels for user 3 :\n",
      "blue moon hotel : 5\n",
      "homewood suites las vegas airport : 5\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.996907332713799\n",
      "comfort inn midtown manhattan : 4.996907332713798\n",
      "allerton hotel : 4.9849054020480885\n",
      "serrano hotel a kimpton hotel : 4.9574337074161665\n",
      "four seasons hotel san francisco : 4.948217391789254\n",
      "the bowery hotel : 4.937430263528778\n",
      "hotel vitale : 4.937430263528778\n",
      "the peninsula chicago : 4.933398035411475\n",
      "\n",
      "\n",
      "Top 10 hotels for user 3  (item-based):\n",
      "kitano new york : 5\n",
      "best western hospitality house : 4.920003316334549\n",
      "omni san francisco hotel : 4.842450737561286\n",
      "columbus motor inn : 4.82953612873261\n",
      "plaza athenee hotel : 4.692137807975122\n",
      "hilton club new york : 4.669006284896156\n",
      "w san francisco : 4.5849234535079315\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.50245750656698\n",
      "courtyard new york manhattan midtown east : 4.458656265040781\n",
      "the talbott hotel : 4.456145034966841\n",
      "\n",
      "\n",
      "Top 10 hotels for user 2000  (who has no reviews whatsoever):\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.509093004901597\n",
      "courtyard new york manhattan midtown east : 4.465291763375398\n",
      "the talbott hotel : 4.4627805333014585\n",
      "the mark : 4.460600367487\n",
      "carlton inn midway : 4.456871255400621\n",
      "hampton inn majestic chicago : 4.431775011894604\n",
      "the hampton inn times square north : 4.430601100429042\n",
      "springhill suites chicago downtown river north : 4.424402550903542\n",
      "the blakely new york : 4.412183320157887\n",
      "four seasons hotel las vegas : 4.411622117604449\n",
      "\n",
      "\n",
      "Top 10 hotels for user 2100  (who has no reviews whatsoever either):\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.509093004901597\n",
      "courtyard new york manhattan midtown east : 4.465291763375398\n",
      "the talbott hotel : 4.4627805333014585\n",
      "the mark : 4.460600367487\n",
      "carlton inn midway : 4.456871255400621\n",
      "hampton inn majestic chicago : 4.431775011894604\n",
      "the hampton inn times square north : 4.430601100429042\n",
      "springhill suites chicago downtown river north : 4.424402550903542\n",
      "the blakely new york : 4.412183320157887\n",
      "four seasons hotel las vegas : 4.411622117604449\n"
     ]
    }
   ],
   "source": [
    "# import specific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "# read data\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "# train kNN-Baseline on the whole collection (both, user and item-wise)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = KNNBaseline()\n",
    "algo.fit(trainset)\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo_items = KNNBaseline(sim_options=sim_options)\n",
    "algo_items.fit(trainset)\n",
    "\n",
    "######################################################################\n",
    "# Best hotels for user XX\n",
    "# list of hotels...\n",
    "hoteldf = pd.read_csv('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv', header=None, names=['item', 'rating','user'])\n",
    "hotels = hoteldf['item'].unique().tolist()\n",
    "\n",
    "# case 1\n",
    "user1 = '3'\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user1, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user1, ':')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 1.5\n",
    "user1 = '3'\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo_items.predict(user1, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user1, ' (item-based):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 2\n",
    "user2 = '2000' # there's 1789 users with ratings...\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user2, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user2, ' (who has no reviews whatsoever):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 3\n",
    "user2 = '2100' # there's 1789 users with ratings...\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user2, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user2, ' (who has no reviews whatsoever either):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the kimberly hotel\n",
      "sofitel chicago water tower\n",
      "the peninsula chicago\n",
      "lowell hotel\n",
      "the plaza\n",
      "the gem hotel chelsea\n",
      "greenwich hotel\n",
      "sofitel new york\n",
      "the carlyle a rosewood hotel\n",
      "the ritz carlton\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Hotels similar to XX\n",
    "hotel = 'courtyard by marriott new york manhattan upper east side'\n",
    "\n",
    "# need to convert hotel to id\n",
    "h_inner_id = algo.trainset.to_inner_iid(hotel)\n",
    "\n",
    "# neigbouring ids\n",
    "hotel_neighbors = algo_items.get_neighbors(h_inner_id, k=10)\n",
    "\n",
    "# take them back to names\n",
    "hotel_neighbors = (algo_items.trainset.to_raw_iid(inner_id) for inner_id in hotel_neighbors)\n",
    "\n",
    "# boom\n",
    "for hotl in hotel_neighbors:\n",
    "    print(hotl)\n",
    "\n",
    "\n",
    "# most popular hotels? From original dataset, we want the higest average given a minimum number of ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
